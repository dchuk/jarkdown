---
phase: "02"
plan: "04"
title: "Custom Field Rendering & Integration"
wave: 2
depends_on: ["02-PLAN-01", "02-PLAN-02", "02-PLAN-03"]
skills_used:
  - python-testing-patterns
must_haves:
  - "New file `src/jarkdown/custom_field_renderer.py` with `CustomFieldRenderer` class"
  - "Type-aware rendering: option → value, user → displayName, date → formatted, array → comma-joined"
  - "Generic fallback via value shape inspection when schema type unavailable"
  - "Custom text area fields with ADF content parsed through `_parse_adf_to_markdown()`"
  - "`_compose_custom_fields_section()` method on MarkdownConverter renders `## Custom Fields` body section"
  - "Custom fields ordered alphabetically by display name"
  - "Empty/null custom fields skipped (only non-null values rendered)"
  - "`compose_markdown()` accepts optional `field_cache` and `field_filter` params and renders custom fields section"
  - "`export_issue()` in jarkdown.py creates FieldMetadataCache, ConfigManager, refreshes cache, passes to converter"
  - "`--include-fields`, `--exclude-fields`, `--refresh-fields` CLI flags fully wired to export pipeline"
  - "`pytest tests/test_custom_fields.py` passes"
  - "`pytest tests/test_integration_phase02.py` passes"
  - "All existing tests in tests/ still pass"
---

## Objective

Create a custom field renderer with type-aware value formatting, integrate it into MarkdownConverter as a `## Custom Fields` section, and wire the full pipeline: CLI args → ConfigManager → FieldMetadataCache → CustomFieldRenderer → compose_markdown output.

## Context

Read these files before starting:
- `@src/jarkdown/markdown_converter.py` — add `_compose_custom_fields_section()` method, modify `compose_markdown()` signature and body
- `@src/jarkdown/jarkdown.py` — modify `export_issue()` to create cache/config, modify `main()` to pass CLI args
- `@src/jarkdown/field_cache.py` — created by Plan 02, provides FieldMetadataCache
- `@src/jarkdown/config_manager.py` — created by Plan 03, provides ConfigManager
- `@.vbw-planning/phases/02-custom-fields-adf/02-CONTEXT.md` — custom field rendering decisions
- `@.vbw-planning/phases/02-custom-fields-adf/02-RESEARCH.md` — field type patterns

This plan depends on Plans 01, 02, and 03 completing first (Wave 2). It modifies `markdown_converter.py` (safe now that Plan 01 is done) and `jarkdown.py` (CLI wiring).

Custom field type rendering rules (from 02-CONTEXT.md):
- String → as-is
- Dict with `value` key → extract value (option/select fields)
- Dict with `displayName` key → extract displayName (user/people fields)
- Dict with `type: "doc"` → parse through ADF parser (rich text areas)
- List → comma-join extracted values (multi-select, labels-like)
- Number → string representation
- Date string → as-is (already formatted)
- Generic fallback → `str(value)`

Open decisions (Claude's discretion):
- Order: alphabetical by display name
- Null handling: skip null values (only render fields with values)

## Tasks

### Task 1: Implement CustomFieldRenderer

Create `src/jarkdown/custom_field_renderer.py`:

```python
"""Renderer for Jira custom fields with type-aware formatting."""

import logging


class CustomFieldRenderer:
    """Renders custom field values based on field type metadata."""

    def __init__(self, adf_parser=None):
        """Initialize the custom field renderer.

        Args:
            adf_parser: Callable that converts ADF dict to markdown string.
                        Typically MarkdownConverter._parse_adf_to_markdown.
        """
        self.logger = logging.getLogger(__name__)
        self._adf_parser = adf_parser

    def render_value(self, value, schema=None):
        """Render a custom field value to markdown string.

        Uses schema type for type-aware rendering when available,
        falls back to value shape inspection.

        Args:
            value: The field value from Jira API (any type).
            schema: Field schema dict with 'type' key, or None.

        Returns:
            str: Markdown-formatted string representation, or None if value is empty.
        """
        if value is None:
            return None

        # Try schema-based rendering first
        if schema:
            schema_type = schema.get("type", "")
            rendered = self._render_by_schema(value, schema_type)
            if rendered is not None:
                return rendered

        # Fall back to value shape inspection
        return self._render_by_shape(value)

    def _render_by_schema(self, value, schema_type):
        """Render value based on schema type.

        Args:
            value: Field value.
            schema_type: Schema type string (string, number, option, user, date, array, etc.)

        Returns:
            str or None: Rendered string, or None if type not recognized.
        """
        if schema_type in ("string", "number"):
            return str(value)
        elif schema_type == "date":
            return str(value)
        elif schema_type == "datetime":
            return str(value)[:19] if len(str(value)) > 19 else str(value)
        elif schema_type == "option":
            if isinstance(value, dict):
                return value.get("value", str(value))
            return str(value)
        elif schema_type == "user":
            if isinstance(value, dict):
                return value.get("displayName", value.get("name", str(value)))
            return str(value)
        elif schema_type == "array":
            return self._render_array(value)
        elif schema_type in ("any",):
            # ADF rich text fields often have schema type "any"
            return self._render_by_shape(value)
        return None

    def _render_array(self, value):
        """Render an array field value.

        Args:
            value: List of values (options, users, strings, etc.)

        Returns:
            str: Comma-joined string of rendered items.
        """
        if not isinstance(value, list):
            return str(value)
        if not value:
            return None

        items = []
        for item in value:
            if isinstance(item, dict):
                # Try common dict patterns
                text = (
                    item.get("value")
                    or item.get("displayName")
                    or item.get("name")
                    or str(item)
                )
                items.append(str(text))
            else:
                items.append(str(item))
        return ", ".join(items)

    def _render_by_shape(self, value):
        """Render value by inspecting its shape (generic fallback).

        Args:
            value: Any value from Jira API.

        Returns:
            str: Rendered string, or None if value is effectively empty.
        """
        if isinstance(value, str):
            return value if value else None

        if isinstance(value, (int, float)):
            return str(value)

        if isinstance(value, dict):
            # ADF document
            if value.get("type") == "doc" and self._adf_parser:
                rendered = self._adf_parser(value)
                return rendered if rendered else None

            # Option/select field
            if "value" in value:
                return str(value["value"])

            # User/people field
            if "displayName" in value:
                return str(value["displayName"])

            # Named entity
            if "name" in value:
                return str(value["name"])

            return str(value)

        if isinstance(value, list):
            return self._render_array(value)

        return str(value) if value is not None else None
```

Commit: `feat(phase-02): implement custom field renderer`

### Task 2: Add _compose_custom_fields_section to MarkdownConverter

Add a new method to MarkdownConverter after `_compose_worklogs_section()` and before `_compose_comments_section()`:

```python
def _compose_custom_fields_section(self, issue_data, field_cache=None, field_filter=None):
    """Compose the custom fields section of the markdown.

    Args:
        issue_data: Raw issue data from Jira API
        field_cache: FieldMetadataCache instance for name resolution, or None.
        field_filter: Dict with 'include'/'exclude' keys from ConfigManager, or None.

    Returns:
        list: Lines of markdown content for custom fields section, or empty list.
    """
    from .custom_field_renderer import CustomFieldRenderer

    fields = issue_data.get("fields", {})

    # Collect custom fields with non-null values
    custom_fields = {}
    for key, value in fields.items():
        if not key.startswith("customfield_"):
            continue
        if value is None:
            continue

        # Resolve display name
        if field_cache:
            display_name = field_cache.get_field_name(key)
        else:
            display_name = key

        # Apply field filter
        if field_filter:
            from .config_manager import ConfigManager
            cm = ConfigManager.__new__(ConfigManager)
            if not cm.should_include_field(display_name, field_filter):
                continue

        custom_fields[display_name] = (key, value)

    if not custom_fields:
        return []

    # Sort alphabetically by display name
    sorted_fields = sorted(custom_fields.items(), key=lambda x: x[0].lower())

    # Render values
    renderer = CustomFieldRenderer(adf_parser=self._parse_adf_to_markdown)

    lines = ["## Custom Fields", ""]
    for display_name, (field_id, value) in sorted_fields:
        schema = field_cache.get_field_schema(field_id) if field_cache else None
        rendered = renderer.render_value(value, schema)
        if rendered is None:
            continue

        # Multi-line values (e.g., ADF content) get their own block
        if "\n" in rendered:
            lines.append(f"### {display_name}")
            lines.append("")
            lines.append(rendered)
            lines.append("")
        else:
            lines.append(f"- **{display_name}:** {rendered}")

    lines.append("")
    return lines
```

Update `compose_markdown()` method signature and body:

1. Add optional parameters to the method signature:
```python
def compose_markdown(self, issue_data, downloaded_attachments, field_cache=None, field_filter=None):
```

2. Add custom fields section call AFTER the worklogs section and BEFORE the comments section. Insert these lines after `lines.extend(self._compose_worklogs_section(issue_data))`:

```python
# Custom Fields section (only if custom fields present)
custom_field_lines = self._compose_custom_fields_section(
    issue_data, field_cache=field_cache, field_filter=field_filter
)
if custom_field_lines:
    lines.extend(custom_field_lines)
```

IMPORTANT: Fix the `_compose_custom_fields_section` to use `should_include_field` as a static-like call. Replace the awkward `ConfigManager.__new__` pattern with a direct implementation:

```python
# Apply field filter (inline check to avoid import)
if field_filter:
    if display_name in field_filter.get("exclude", set()):
        continue
    include_set = field_filter.get("include")
    if include_set is not None and display_name not in include_set:
        continue
```

Commit: `feat(phase-02): add custom fields section to markdown output`

### Task 3: Wire CLI to export pipeline

Modify `export_issue()` in `jarkdown.py` to:
1. Accept new parameters: `refresh_fields=False`, `include_fields=None`, `exclude_fields=None`
2. Create FieldMetadataCache and refresh it
3. Create ConfigManager and get field filter
4. Pass field_cache and field_filter to compose_markdown()

Updated function:

```python
def export_issue(api_client, issue_key, output_dir=None,
                 refresh_fields=False, include_fields=None, exclude_fields=None):
```

Add after `markdown_converter = MarkdownConverter(...)`:

```python
# Set up field metadata cache and config
from .field_cache import FieldMetadataCache
from .config_manager import ConfigManager

field_cache = FieldMetadataCache(api_client.domain)
field_cache.refresh(api_client, force=refresh_fields)

config_manager = ConfigManager()
field_filter = config_manager.get_field_filter(
    cli_include=include_fields,
    cli_exclude=exclude_fields,
)
```

Update the `compose_markdown()` call:
```python
markdown_content = markdown_converter.compose_markdown(
    issue_data, downloaded_attachments,
    field_cache=field_cache, field_filter=field_filter,
)
```

Update `main()` to pass CLI args to `export_issue()`:
```python
export_issue(
    api_client, args.issue_key, args.output,
    refresh_fields=args.refresh_fields,
    include_fields=args.include_fields,
    exclude_fields=args.exclude_fields,
)
```

Note: `args.refresh_fields`, `args.include_fields`, `args.exclude_fields` were added by Plans 02 and 03. If the attributes don't exist yet (due to execution order), use `getattr(args, 'refresh_fields', False)` etc. for safety.

Commit: `feat(phase-02): wire custom fields pipeline to CLI`

### Task 4: Write custom field renderer tests

Create `tests/test_custom_fields.py`:

```python
@pytest.fixture
def renderer():
    """Create a CustomFieldRenderer without ADF parser."""
    return CustomFieldRenderer()

@pytest.fixture
def renderer_with_adf():
    """Create a CustomFieldRenderer with ADF parser."""
    converter = MarkdownConverter("https://example.atlassian.net", "example.atlassian.net")
    return CustomFieldRenderer(adf_parser=converter._parse_adf_to_markdown)
```

**TestCustomFieldRenderer** class:
- `test_string_value`: `"hello"` → `"hello"`
- `test_number_value`: `42` → `"42"`
- `test_none_value`: `None` → `None`
- `test_option_value`: `{"value": "High", "id": "1"}` → `"High"`
- `test_user_value`: `{"displayName": "John Doe", "accountId": "abc"}` → `"John Doe"`
- `test_date_value`: `"2025-01-15"` → `"2025-01-15"`
- `test_array_of_options`: `[{"value": "A"}, {"value": "B"}]` → `"A, B"`
- `test_array_of_users`: `[{"displayName": "Alice"}, {"displayName": "Bob"}]` → `"Alice, Bob"`
- `test_array_of_strings`: `["tag1", "tag2"]` → `"tag1, tag2"`
- `test_empty_array`: `[]` → `None`
- `test_empty_string`: `""` → `None`
- `test_adf_document`: ADF dict with `type: "doc"` + paragraphs → parsed markdown (uses renderer_with_adf)
- `test_unknown_dict_fallback`: `{"foo": "bar"}` → `str({"foo": "bar"})`

**TestSchemaBasedRendering** class:
- `test_option_schema`: value `{"value": "X"}`, schema `{"type": "option"}` → `"X"`
- `test_user_schema`: value `{"displayName": "Y"}`, schema `{"type": "user"}` → `"Y"`
- `test_array_schema`: value `[{"value": "A"}]`, schema `{"type": "array"}` → `"A"`
- `test_number_schema`: value `3.14`, schema `{"type": "number"}` → `"3.14"`

**TestCustomFieldsSection** class (uses MarkdownConverter):
- `test_custom_fields_rendered`: Issue data with customfield_10001 (string), customfield_10002 (option dict) → `## Custom Fields` section with both fields
- `test_custom_fields_alphabetical_order`: Multiple fields → sorted by display name
- `test_null_fields_skipped`: customfield with None value → not in output
- `test_custom_fields_with_filter_include`: Only included fields appear
- `test_custom_fields_with_filter_exclude`: Excluded fields absent
- `test_no_custom_fields`: Issue with no customfield_ keys → no section
- `test_adf_custom_field`: customfield with ADF value → rendered as markdown under `###` heading

Create a test fixture `tests/data/issue_with_custom_fields.json`:
- Standard issue fields plus 4 custom fields:
  - `customfield_10001`: string value `"5"` (Story Points)
  - `customfield_10002`: option `{"value": "Team Alpha", "id": "100"}`
  - `customfield_10003`: user `{"displayName": "Jane Smith", "accountId": "abc123"}`
  - `customfield_10004`: `null` (should be skipped)
  - `customfield_10005`: array `[{"value": "Q1"}, {"value": "Q2"}]`

Commit: `test(phase-02): add custom field renderer and section tests`

### Task 5: Write integration tests

Create `tests/test_integration_phase02.py` — end-to-end tests verifying the full Phase 2 pipeline:

**TestAdfIntegration** class:
- `test_adf_table_in_compose`: Issue with ADF description containing a table → compose_markdown output includes pipe-delimited table
- `test_adf_panel_in_compose`: Issue with ADF description containing a panel → compose_markdown output includes blockquote with prefix
- `test_adf_mixed_content`: Issue with ADF description containing heading + table + bullet list + panel → all rendered correctly

**TestCustomFieldIntegration** class:
- `test_custom_fields_full_pipeline`: Load `issue_with_custom_fields.json`, create mock FieldMetadataCache that resolves field names, call compose_markdown with cache → verify `## Custom Fields` section has resolved names and formatted values
- `test_custom_fields_without_cache`: Same issue, no cache → fields appear with raw `customfield_XXXXX` IDs
- `test_field_filter_integration`: Use field_filter to exclude one field → verify it's absent from output
- `test_compose_markdown_backward_compatible`: Existing tests' calling pattern (`compose_markdown(issue_data, attachments)` without new params) still works

Create ADF-rich test fixture `tests/data/issue_with_adf_rich.json`:
- Issue with ADF description containing: a table (2×2), an info panel, a taskList with 2 items, an emoji, and a horizontal rule
- Standard fields for complete output

Verify all existing tests still pass:
```bash
pytest tests/ -v
```

Commit: `test(phase-02): add phase 2 integration tests`

## Verification

```bash
pytest tests/test_custom_fields.py -v
pytest tests/test_integration_phase02.py -v
pytest tests/ -v  # ALL tests pass
```

## Success Criteria

- CustomFieldRenderer handles all Jira field types with schema-aware rendering
- Generic fallback works for unknown field types via value shape inspection
- ADF custom fields parsed through existing ADF parser
- Custom Fields section appears in markdown output when custom fields exist
- Fields sorted alphabetically by display name
- Null fields skipped, only non-null values rendered
- CLI flags (--include-fields, --exclude-fields, --refresh-fields) fully wired
- ConfigManager → FieldMetadataCache → CustomFieldRenderer pipeline works end-to-end
- Backward compatibility: compose_markdown works without new params
- All tests pass (93 existing + new)
